import os
from dotenv import load_dotenv
from supabase import create_client, Client
from sentence_transformers import SentenceTransformer
from zhipuai import ZhipuAI

# 1. åŠ è½½é…ç½®
load_dotenv()
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
ZHIPU_API_KEY = os.getenv("ZHIPU_API_KEY")

if not ZHIPU_API_KEY:
    print("âŒ é”™è¯¯: è¯·å…ˆåœ¨ .env ä¸­å¡«å…¥ ZHIPU_API_KEY")
    exit()

# 2. åˆå§‹åŒ–å®¢æˆ·ç«¯
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
zhipu_client = ZhipuAI(api_key=ZHIPU_API_KEY)

print("â³ æ­£åœ¨åŠ è½½åµŒå…¥æ¨¡å‹ (ç”¨äºæœç´¢)...")
# æœ¬åœ°æ¨¡å‹ï¼Œç”¨äºæŠŠé—®é¢˜å˜æˆå‘é‡
embed_model = SentenceTransformer('shibing624/text2vec-base-chinese')

def get_relevant_laws(query: str):
    """ å»æ•°æ®åº“æœç´¢ç›¸å…³çš„æ³•å¾‹æ¡æ¬¾ """
    query_vector = embed_model.encode(query).tolist()
    
    response = supabase.rpc("match_documents", {
        "query_embedding": query_vector,
        "match_threshold": 0.4, # ç¨å¾®æ”¾å®½ä¸€ç‚¹ï¼Œç¡®ä¿èƒ½æœåˆ°ä¸œè¥¿
        "match_count": 5        # ç»™ AI æä¾›å‰ 5 æ¡ç›¸å…³æ³•å¾‹
    }).execute()
    
    return response.data

def ask_lawyer_glm(user_question: str):
    """ æ ¸å¿ƒå‡½æ•°ï¼šRAG æµç¨‹ """
    print(f"\nThinking... (æ­£åœ¨æŸ¥é˜…æ³•å…¸å¹¶å’¨è¯¢ GLM-4)")
    
    # 1. æ£€ç´¢ (Retrieve)
    relevant_docs = get_relevant_laws(user_question)
    
    if not relevant_docs:
        print("ğŸ¤·â€â™‚ï¸ æŠ±æ­‰ï¼Œæ•°æ®åº“é‡Œæ²¡æ‰¾åˆ°ç›¸å…³æ³•å¾‹ï¼Œä½†æˆ‘ä¼šå°è¯•ç”¨é€šç”¨çŸ¥è¯†å›ç­”ã€‚")
        context_text = "ï¼ˆæœªæ‰¾åˆ°å…·ä½“æ³•å¾‹æ¡æ–‡ï¼Œè¯·ä¾æ®é€šç”¨æ³•å¾‹å¸¸è¯†å›ç­”ï¼‰"
    else:
        # æŠŠæœåˆ°çš„å‡ æ¡æ³•å¾‹æ‹¼æˆä¸€æ®µè¯
        context_text = "\n\n".join([
            f"ã€Š{doc['law_name']}ã€‹{doc['reference_id']}:\n{doc['content']}" 
            for doc in relevant_docs
        ])

    # 2. ç»„è£…æç¤ºè¯ (Prompt Engineering)
    # è¿™æ˜¯ RAG çš„çµé­‚ï¼šå‘Šè¯‰ AI "åˆ©ç”¨ä¸Šé¢çš„èµ„æ–™å›ç­”ä¸‹é¢çš„é—®é¢˜"
    system_prompt = """
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ä¸­å›½æ³•å¾‹é¡¾é—®ã€‚è¯·æ ¹æ®ä¸‹é¢æä¾›çš„ã€æ³•å¾‹æ³•è§„ä¾æ®ã€‘æ¥å›ç­”ç”¨æˆ·çš„æé—®ã€‚
è¦æ±‚ï¼š
1. å¼•ç”¨å…·ä½“çš„æ³•å¾‹æ¡æ¬¾åç§°ï¼ˆå¦‚ã€Šæ°‘æ³•å…¸ã€‹ç¬¬ä¸€åƒxxxæ¡ï¼‰ã€‚
2. è§£ç­”è¦é€šä¿—æ˜“æ‡‚ï¼Œä½†é€»è¾‘ä¸¥å¯†ã€‚
3. å¦‚æœæä¾›çš„ä¾æ®ä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œè¯·è¯šå®è¯´æ˜ï¼Œä¸è¦çç¼–æ³•å¾‹æ¡æ–‡ã€‚
"""
    
    user_prompt = f"""
ã€æ³•å¾‹æ³•è§„ä¾æ®ã€‘ï¼š
{context_text}

ã€ç”¨æˆ·é—®é¢˜ã€‘ï¼š
{user_question}
"""

    # 3. ç”Ÿæˆ (Generate) - è°ƒç”¨ GLM-4
    try:
        response = zhipu_client.chat.completions.create(
            model="glm-4",  # è¿™é‡Œä½¿ç”¨ GLM-4 æ¨¡å‹
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            stream=True, # å¼€å¯æµå¼è¾“å‡ºï¼Œåƒæ‰“å­—æœºä¸€æ ·
        )
        
        print("\nğŸ¤– === AI å¾‹å¸ˆçš„å›ç­” ===\n")
        # å®æ—¶æ‰“å°ç»“æœ
        for chunk in response:
            print(chunk.choices[0].delta.content or "", end="")
        print("\n\n" + "="*30)
        
    except Exception as e:
        print(f"âŒ è°ƒç”¨ GLM-4 å‡ºé”™: {e}")

if __name__ == "__main__":
    while True:
        question = input("\nè¯·ç®€è¿°æ‚¨çš„æ³•å¾‹é—®é¢˜ (è¾“å…¥ q é€€å‡º): ")
        if question.lower() in ['q', 'quit', 'exit']:
            break
        
        ask_lawyer_glm(question)