import os
import json
import time
import re
from typing import List, Dict
from dotenv import load_dotenv
from supabase import create_client, Client
from openai import OpenAI  # ğŸ‘ˆ æ”¹ç”¨ OpenAI åº“
from tqdm import tqdm

# 1. åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
SILICONFLOW_API_KEY = os.getenv("SILICONFLOW_API_KEY") # ğŸ‘ˆ æ–° Key

if not all([SUPABASE_URL, SUPABASE_KEY, SILICONFLOW_API_KEY]):
    print("âŒ é”™è¯¯: ç¯å¢ƒå˜é‡ç¼ºå¤±ï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶ï¼")
    exit()

# 2. åˆå§‹åŒ–å®¢æˆ·ç«¯
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# ğŸ‘‡ åˆå§‹åŒ– SiliconFlow å®¢æˆ·ç«¯ (å…¼å®¹ OpenAI æ ¼å¼)
client = OpenAI(
    api_key=SILICONFLOW_API_KEY,
    base_url="https://api.siliconflow.cn/v1"
)

print("ğŸš€ å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ (SiliconFlow)ã€‚å‡†å¤‡å¼€å§‹å¤„ç†æ•°æ®...")

# ---------------- å·¥å…·å‡½æ•° ----------------

def get_embedding(text: str):
    """ è°ƒç”¨ SiliconFlow è·å– BGE-M3 å‘é‡ (1024ç»´) """
    for _ in range(3):
        try:
            # âœ… è¿™é‡Œä½¿ç”¨ç¡…åŸºæµåŠ¨çš„å…è´¹å‘é‡æ¨¡å‹ BAAI/bge-m3
            response = client.embeddings.create(
                model="BAAI/bge-m3", 
                input=text
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"   âš ï¸ API æ³¢åŠ¨: {e}ï¼Œæ­£åœ¨é‡è¯•...")
            time.sleep(1)
    print("   âŒ Embedding å¤±è´¥ï¼Œè·³è¿‡æ­¤æ¡")
    return None

def check_if_exists(title_prefix: str) -> bool:
    try:
        response = supabase.table("documents").select("id").ilike("title", f"{title_prefix}%").limit(1).execute()
        return len(response.data) > 0
    except Exception:
        return False

def chunk_text(text: str, chunk_size=500, overlap=50) -> List[str]:
    if not text: return []
    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunks.append(text[start:end])
        start += (chunk_size - overlap)
    return chunks

def batch_insert(records: List[Dict]):
    if not records: return
    try:
        supabase.table("documents").insert(records).execute()
    except Exception as e:
        print(f"   âš ï¸ æ•°æ®åº“å†™å…¥å¤±è´¥: {e}")

# ---------------- é€»è¾‘ 1: å¤„ç†æ°‘æ³•å…¸ ----------------

def process_minfadian(file_path: str):
    print(f"\nğŸ“˜ [1/3] å¤„ç†: æ°‘æ³•å…¸...")
    if not os.path.exists(file_path): return

    if check_if_exists("æ°‘æ³•å…¸"):
        print("   â© å·²å­˜åœ¨ï¼Œè·³è¿‡ã€‚")
        return

    with open(file_path, 'r', encoding='utf-8') as f:
        text = f.read()

    pattern = r"(ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ]+æ¡\s+)"
    parts = re.split(pattern, text)
    
    current_clause = ""
    batch_records = []
    
    for i in tqdm(range(0, len(parts)), desc="å¤„ç†æ³•æ¡"):
        part = parts[i]
        if re.match(pattern, part):
            current_clause = part.strip()
        else:
            if current_clause and part.strip():
                content = f"{current_clause} {part.strip()}"
                embedding = get_embedding(content)
                if embedding:
                    batch_records.append({
                        "title": f"æ°‘æ³•å…¸ {current_clause}", 
                        "content": content,
                        "embedding": embedding,
                        "user_id": None 
                    })
                if len(batch_records) >= 10:
                    batch_insert(batch_records)
                    batch_records = []
                current_clause = ""
    if batch_records: batch_insert(batch_records)

# ---------------- é€»è¾‘ 2: å¤„ç† LeCaRD æ¡ˆä¾‹ ----------------

def process_lecard(folder_path: str):
    print(f"\nğŸ“‚ [2/3] å¤„ç†: LeCaRD æ¡ˆä¾‹...")
    if not os.path.exists(folder_path): return

    files = []
    for root, _, filenames in os.walk(folder_path):
        for filename in filenames:
            if filename.endswith('.json'):
                files.append(os.path.join(root, filename))
    
    for file_path in tqdm(files, desc="å¤„ç†æ¡ˆä¾‹"):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            case_name = data.get('ajName', os.path.basename(file_path))
            
            if check_if_exists(f"æ¡ˆä¾‹: {case_name}"): continue

            content = data.get('qw', '') or (data.get('ajjbqk', '') + "\n" + data.get('pjjg', '')).strip()
            if not content: continue

            chunks = chunk_text(content)
            batch_records = []
            for chunk in chunks:
                embedding = get_embedding(chunk)
                if embedding:
                    batch_records.append({
                        "title": f"æ¡ˆä¾‹: {case_name}",
                        "content": chunk,
                        "embedding": embedding,
                        "user_id": None
                    })
            batch_insert(batch_records)
        except Exception: pass

# ---------------- é€»è¾‘ 3: å¤„ç†æ™®é€š TXT ----------------

def process_general_txt(data_dir: str):
    print(f"\nğŸ“„ [3/3] å¤„ç†: å…¶ä»– TXT...")
    if not os.path.exists(data_dir): return

    for filename in os.listdir(data_dir):
        if filename.endswith(".txt") and "minfadian" not in filename:
            if check_if_exists(f"å‚è€ƒèµ„æ–™: {filename}"): continue
            
            file_path = os.path.join(data_dir, filename)
            with open(file_path, 'r', encoding='utf-8') as f:
                text = f.read()
            
            chunks = chunk_text(text)
            batch_records = []
            for chunk in tqdm(chunks, desc=filename, leave=False):
                embedding = get_embedding(chunk)
                if embedding:
                    batch_records.append({
                        "title": f"å‚è€ƒèµ„æ–™: {filename}",
                        "content": chunk,
                        "embedding": embedding,
                        "user_id": None
                    })
                if len(batch_records) >= 10:
                    batch_insert(batch_records)
                    batch_records = []
            if batch_records: batch_insert(batch_records)

if __name__ == "__main__":
    # æ‰§è¡Œå¤„ç†
    process_minfadian("data/minfadian.txt")
    process_lecard("data/lecard_cases")
    process_general_txt("data")
    print("\nğŸ‰ å…¨éƒ¨å®Œæˆï¼")